{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "#this class will take in the relevant data and return the\n",
    "#data in desired format and transformations for analysis\n",
    "class fix_data:\n",
    "\n",
    "     #upload and explore Case-Schiller HPI data\n",
    "    def cleanup_data(CS, PC, MG, verb=False, logz=False):\n",
    "        CS_dat = pd.read_csv(CS)\n",
    "        CS_dat['DATE'] =  pd.to_datetime(CS_dat['DATE'], infer_datetime_format=True)\n",
    "        CS_dat = CS_dat.set_index('DATE')\n",
    "\n",
    "        #import personal expenditures to adjust for inflation over time\n",
    "        #https://www.bea.gov/iTable/iTable.cfm?reqid=19&step=2#reqid=19&step=3&isuri=1&1910=x&0=-\n",
    "        #99&1921=survey&1903=64&1904=1987&1905=2018&1906=q&1911=0\n",
    "        p_exp = pd.read_csv(PC)\n",
    "        p_exp = p_exp.drop(['Table 2.3.4. Price Indexes for Personal Consumption Expenditures by Major Type of Product'], axis=1)\n",
    "        PCE = p_exp.iloc[[3,4,5]]\n",
    "        PCE = PCE.drop(['Unnamed: 1'], axis = 1)\n",
    "\n",
    "        #interpolate the PCE data to take it from quarterly to monthly using the\n",
    "        #pandas interpolation\n",
    "        for j in range(125):\n",
    "            if PCE.iloc[1][j] == \"Q1\":\n",
    "                PCE.iloc[0][j] = PCE.iloc[0][j] + '-01-01'\n",
    "            elif PCE.iloc[1][j] == \"Q2\":\n",
    "                PCE.iloc[0][j] = PCE.iloc[0][j] + '-04-01'\n",
    "            elif PCE.iloc[1][j] == \"Q3\":\n",
    "                PCE.iloc[0][j] = PCE.iloc[0][j] + '-07-01'\n",
    "            else:\n",
    "                PCE.iloc[0][j] = PCE.iloc[0][j] + '-10-01'\n",
    "\n",
    "        for f in range(125):\n",
    "            PCE.iloc[0][f]= pd.to_datetime(PCE.iloc[0][f],infer_datetime_format=True )\n",
    "        PCE = PCE.drop([4])\n",
    "\n",
    "        new_PCE = pd.DataFrame([], columns=['Date', 'pce'])\n",
    "        new_PCE['Date'] = PCE.iloc[0]\n",
    "        new_PCE['pce'] = PCE.iloc[1]\n",
    "        new_PCE = new_PCE.set_index('Date')\n",
    "        new_PCE = new_PCE.resample('MS').asfreq()\n",
    "        new_PCE['pce'] = pd.to_numeric(new_PCE['pce'])\n",
    "        new_PCE = new_PCE.interpolate()\n",
    "\n",
    "        #adjust the CS raw values using the personal consumption expenditures\n",
    "        #from the most recent quarter value reported\n",
    "        #(since PCE is quarterly and CS is monthly)\n",
    "        adj_CS_dat = CS_dat.copy(deep=True)\n",
    "        adj_CS_dat.iloc[[0],[0]] = 0.0\n",
    "\n",
    "        for j in range(len(new_PCE)):\n",
    "             adj_CS_dat.iloc[[j],[0]] = CS_dat.iloc[[j],[0]].values / (new_PCE.iloc[j].values)\n",
    "        adj_CS_dat = adj_CS_dat.drop(pd.to_datetime('2018-02-01'))\n",
    "\n",
    "\n",
    "        #update so that the variable is log of the percentage change in HPI\n",
    "        perc_adj_CS_dat = adj_CS_dat.copy(deep=True)\n",
    "        perc_adj_CS_dat.iloc[[0]] = 0\n",
    "\n",
    "        if logz==True:\n",
    "            for p in range(1,len(adj_CS_dat)):\n",
    "                perc_adj_CS_dat.iloc[[p],[0]] = np.log((adj_CS_dat.iloc[[p],[0]].values - adj_CS_dat.iloc[[p-1],[0]].values)/adj_CS_dat.iloc[[p-1],[0]].values +1.)\n",
    "        if logz==False:\n",
    "            for p in range(1,len(adj_CS_dat)):\n",
    "                perc_adj_CS_dat.iloc[[p],[0]] = (adj_CS_dat.iloc[[p],[0]].values - adj_CS_dat.iloc[[p-1],[0]].values)/adj_CS_dat.iloc[[p-1],[0]].values\n",
    "\n",
    "        #update so that the mortage data is percentage change month to month\n",
    "        #import the mortgage data\n",
    "        mdo_dat = pd.read_csv(MG)\n",
    "\n",
    "        #get rid of data before 1987 since that is when CS data starts\n",
    "        for j in range(157):\n",
    "            mdo_dat = mdo_dat.drop([j])\n",
    "\n",
    "        perc_adj_mdo_dat = mdo_dat\n",
    "\n",
    "        if verb == True:\n",
    "            filepath = '/Users/abbysuckow/Desktop/'\n",
    "            #plot the CS HPI over time\n",
    "            CS_dat.plot(legend=None)\n",
    "            plt.xlabel('Date', fontsize=10)\n",
    "            plt.ylabel('CS HPI ', fontsize=10)\n",
    "            plt.savefig(filepath+'CSHPI')\n",
    "            plt.show()\n",
    "\n",
    "            #plot the difference adjusted CS HPI over time\n",
    "            adj_CS_dat.plot(legend=None)\n",
    "            plt.xlabel('Date', fontsize=10)\n",
    "            plt.ylabel('Adjusted CS HPI ', fontsize = 10)\n",
    "            plt.savefig(filepath+'adjCSHPI')\n",
    "            plt.show()\n",
    "\n",
    "            #plot the log adjusted CS HPI over time\n",
    "            perc_adj_CS_dat.plot(legend=None)\n",
    "            plt.xlabel('Date', fontsize=10)\n",
    "            plt.ylabel('Percentage change CS HPI ', fontsize = 10)\n",
    "            plt.savefig(filepath+'percchangeHPI')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        return CS_dat, adj_CS_dat, perc_adj_CS_dat, perc_adj_mdo_dat, new_PCE\n",
    "\n",
    "\n",
    "    #function to get 1-4 four family data for the mortage data\n",
    "    #also interpolates data\n",
    "    def get_residential_data(mdo_dat, new_PCE):\n",
    "\n",
    "        #only want 1-4 fam residence values\n",
    "        mdo_dat = mdo_dat.set_index(mdo_dat['Series Description'])\n",
    "        resid = 'One- to four- family'\n",
    "        for label in mdo_dat.columns:\n",
    "            if resid not in label:\n",
    "                mdo_dat = mdo_dat.drop([label], axis = 1)\n",
    "\n",
    "        #interpolate mortgage data to make it monthly from quarterly\n",
    "        #first need to make the index a datetime\n",
    "        mdo_dat.index = pd.to_datetime(mdo_dat.index,infer_datetime_format=True )\n",
    "\n",
    "        #now interpolate\n",
    "        mdo_dat = mdo_dat.resample('MS').asfreq()\n",
    "        for label in mdo_dat.columns:\n",
    "            mdo_dat[label] = pd.to_numeric(mdo_dat[label])\n",
    "        mdo_dat = mdo_dat.interpolate()\n",
    "\n",
    "        #adjust for inflation\n",
    "        adj_mdo_dat = mdo_dat.copy(deep=True)\n",
    "        adj_mdo_dat.iloc[[0],[0]] = 0.0\n",
    "\n",
    "        for j in range(len(new_PCE)):\n",
    "             adj_mdo_dat.iloc[[j],[0]] = mdo_dat.iloc[[j],[0]].values / (new_PCE.iloc[j].values)\n",
    "\n",
    "        return adj_mdo_dat\n",
    "\n",
    "\n",
    "    #function to split data into train, validation and test\n",
    "    #split = the number of data points to include in training\n",
    "    #val = the number of data points to include in the validation set\n",
    "    def ttv_split(dat, split, val):\n",
    "        train = dat[:split]\n",
    "        valid = dat[split+1:split+1+val]\n",
    "        test = dat[split+val+2:len(dat)-1]\n",
    "        return train, valid, test\n",
    "\n",
    "    #this function pulls the Case Shiller out from the dataset to be the target\n",
    "    #variable\n",
    "    def get_target(dat):\n",
    "        y_, X_ = pd.DataFrame(dat['CSUSHPINSA']), pd.DataFrame(dat.drop('CSUSHPINSA', axis=1))\n",
    "        return y_, X_\n",
    "\n",
    "    def split_shift_data(dat, train_size, valid_size, num_lags, dif_order=0, num_dif=0, shift_ord=0,plot=False, second_dif=False, mdo_dat=None, both=True):\n",
    "\n",
    "        sec = 0\n",
    "        #option to difference the data\n",
    "        if dif_order > 0:\n",
    "            for r in range(num_dif):\n",
    "                dat = dat - dat.shift(dif_order)\n",
    "        if second_dif == True:\n",
    "            dat = dat - dat.shift(1)\n",
    "            sec = 1\n",
    "\n",
    "\n",
    "        #add lags for the independent inputs into the model\n",
    "        for l in range(num_lags):\n",
    "            dat['Lag-'+str(l+1)] = dat['CSUSHPINSA'].shift(l+1)\n",
    "\n",
    "        if mdo_dat is not None:\n",
    "            mdo_dat = pd.DataFrame(mdo_dat[str(mdo_dat.iloc[0].index[0])])\n",
    "            for l in range(num_lags):\n",
    "                mdo_dat['MDO Lag-'+str(l+1)] = mdo_dat.iloc[:,0].shift(l+1)\n",
    "            mdo_dat = pd.DataFrame(mdo_dat.drop(str(mdo_dat.columns[0]),axis=1))\n",
    "\n",
    "        dat = pd.concat([dat, mdo_dat], axis=1)\n",
    "        #separete target variable\n",
    "        y_, X_ = pd.DataFrame(dat['CSUSHPINSA']), pd.DataFrame(dat.drop('CSUSHPINSA', axis=1))\n",
    "\n",
    "        #for indexing new data once we lose data to differencing, shifting, etc.\n",
    "        num = (num_dif*dif_order)+num_lags+sec\n",
    "\n",
    "\n",
    "        #split into train valid and test\n",
    "        y_train, X_train= y_[:train_size], X_[:train_size]\n",
    "        y_valid, X_valid = y_[train_size:train_size+valid_size], X_[train_size:train_size+valid_size]\n",
    "        y_test, X_test = y_[train_size+valid_size:len(dat)-1], X_[train_size+valid_size:len(dat)-1]\n",
    "\n",
    "        #if we are shifting the data\n",
    "        if shift_ord>0:\n",
    "            X_train, X_valid, X_test = X_train.shift(shift_ord), X_valid.shift(shift_ord), X_test.shift(shift_ord)\n",
    "            num = (num_dif*dif_order)+num_lags+shift_ord\n",
    "\n",
    "        #add in for a bias term\n",
    "        X_train = sm.add_constant(X_train)\n",
    "        X_valid = sm.add_constant(X_valid)\n",
    "        X_test = sm.add_constant(X_test)\n",
    "\n",
    "        if plot == True:\n",
    "            filepath = '/Users/abbysuckow/Desktop/'\n",
    "            total = pd.concat([y_train[num:].rename(columns={'CSUSHPINSA':'Train'}), y_valid.rename(columns={'CSUSHPINSA':'Validation'}), y_test.rename(columns={'CSUSHPINSA':'Test'})], axis=1)\n",
    "            total.plot()\n",
    "\n",
    "            plt.savefig(filepath+'splitdata')\n",
    "            y_train.plot()\n",
    "            y_valid.plot(color='orange')\n",
    "            y_test.plot(color='green')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        return y_, y_train, X_train, y_valid, X_valid, y_test, X_test, num\n",
    "\n",
    "    def check_stationary(dat, plots=False):\n",
    "\n",
    "        result = adfuller(dat)\n",
    "        print('ADF Statistic: %f' % result[0])\n",
    "        print('p-value: %f' % result[1])\n",
    "\n",
    "        if plots==True:\n",
    "            pd.plotting.autocorrelation_plot(dat)\n",
    "            plt.show()\n",
    "            plot_acf(dat, lags=36)\n",
    "            plt.show()\n",
    "        return\n",
    "\n",
    "\n",
    "    #this function is to transform the data back into the raw Case Shiller\n",
    "    #index values for visualization and error reporting purposes\n",
    "    def switch_back(y_hat, tru_dat, dif_order, month_forecast, adj_dat, PCE_dat):\n",
    "\n",
    "        hmm = y_hat.copy()\n",
    "        holder = tru_dat[:dif_order].copy()\n",
    "\n",
    "        count = np.round(len(hmm)/dif_order).astype(int)\n",
    "        undiff_preds = np.zeros([len(hmm),1])\n",
    "\n",
    "        #get rid of the seasonal differencing\n",
    "        for j in range(count):\n",
    "            for p in range(dif_order):\n",
    "                if (j*dif_order)-1+p >= len(undiff_preds) -1 :\n",
    "                    break\n",
    "                if j == 0:\n",
    "                    undiff_preds[((j*dif_order)+p),0] = hmm.iloc[(j*dif_order)+p,-1] + holder.iloc[p][0]\n",
    "\n",
    "                else:\n",
    "                    undiff_preds[((j*dif_order)+p),0] = hmm.iloc[(j*dif_order)+p,-1] + holder.iloc[p][0]\n",
    "\n",
    "            if j == 0:\n",
    "                holder[:] =  undiff_preds[:dif_order]\n",
    "            else:\n",
    "                if (j*dif_order)-1+p >= len(undiff_preds) -1:\n",
    "                    break\n",
    "                holder[:] = undiff_preds[(j*dif_order):(j*dif_order)+p+1]\n",
    "\n",
    "        unperc_preds = np.zeros(undiff_preds.shape)\n",
    "        #get rid of the percentage change\n",
    "        x_0 = adj_dat.iloc[month_forecast-1]\n",
    "        counter =1\n",
    "        for f in range(len(y_hat)):\n",
    "            counter = counter*(undiff_preds[f,0] +1)\n",
    "            unperc_preds[f,0] = counter*x_0\n",
    "\n",
    "        #get rid of CPI adjustment\n",
    "        unadj_preds = unperc_preds * PCE_dat.values\n",
    "\n",
    "        return unadj_preds\n",
    "\n",
    "    #function to remove seasonality from data based on passed in adjustments\n",
    "    def adjust_months(target_dat, month_dat, adjustments):\n",
    "        new_target_dat = pd.DataFrame(0, index=range(len(target_dat)), columns=range(1))\n",
    "        for j in range(len(month_dat)):\n",
    "            if month_dat.iloc[j][0] == 1.:\n",
    "                new_target_dat.iloc[[j],[0]] = target_dat.iloc[j]- adjustments[0]\n",
    "            elif month_dat.iloc[j][1] == 1.:\n",
    "                new_target_dat.iloc[[j],[0]] = target_dat.iloc[j]- adjustments[1]\n",
    "            elif month_dat.iloc[j][2] == 1.:\n",
    "                new_target_dat.iloc[[j],[0]] = target_dat.iloc[j]- adjustments[2]\n",
    "            elif month_dat.iloc[j][3] == 1.:\n",
    "                new_target_dat.iloc[[j],[0]] = target_dat.iloc[j]- adjustments[3]\n",
    "            elif month_dat.iloc[j][4] == 1.:\n",
    "                new_target_dat.iloc[[j],[0]] = target_dat.iloc[j]- adjustments[4]\n",
    "            elif month_dat.iloc[j][5] == 1.:\n",
    "                new_target_dat.iloc[[j],[0]] = target_dat.iloc[j]- adjustments[5]\n",
    "            elif month_dat.iloc[j][6] == 1.:\n",
    "                new_target_dat.iloc[[j],[0]] = target_dat.iloc[j]- adjustments[6]\n",
    "            elif month_dat.iloc[j][7] == 1.:\n",
    "                new_target_dat.iloc[[j],[0]] = target_dat.iloc[j]- adjustments[7]\n",
    "            elif month_dat.iloc[j][8] == 1.:\n",
    "                new_target_dat.iloc[[j],[0]] = target_dat.iloc[j]- adjustments[8]\n",
    "            elif month_dat.iloc[j][9] == 1.:\n",
    "                new_target_dat.iloc[[j],[0]] = target_dat.iloc[j]- adjustments[9]\n",
    "            elif month_dat.iloc[j][10] == 1.:\n",
    "                new_target_dat.iloc[[j],[0]] = target_dat.iloc[j]- adjustments[10]\n",
    "            else:\n",
    "                new_target_dat.iloc[[j],[0]] = target_dat.iloc[j]\n",
    "\n",
    "        return new_target_dat\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
