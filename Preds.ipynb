{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from Fix_data import fix_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.table as tb\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras import optimizers\n",
    "\n",
    "#this class is used for making predictions using the different models\n",
    "class making_preds:\n",
    "\n",
    "    def optim_model(model_type, X_train, y_train, X_valid, y_valid, num, shift_ord):\n",
    "        \n",
    "        if model_type != 'LSTM':\n",
    "         #normalize data to stabilize SVR\n",
    "            rbX = RobustScaler()\n",
    "            X_train1 = pd.DataFrame(rbX.fit_transform(X_train.iloc[num:,1:]))\n",
    "            X_train1 = X_train1.set_index(X_train[num:].index)\n",
    "            X_train = pd.concat([pd.DataFrame(X_train.iloc[num:,0]), X_train1], axis=1)\n",
    "            rbY = RobustScaler()\n",
    "            y_train = rbY.fit_transform(y_train[num:])\n",
    "            \n",
    "            #normalize validation data \n",
    "            X_valid1 = pd.DataFrame(rbX.transform(X_valid.iloc[shift_ord:,1:]))\n",
    "            X_valid1 = X_valid1.set_index(X_valid[shift_ord:].index)\n",
    "            X_valid = pd.concat([pd.DataFrame(X_valid.iloc[shift_ord:,0]), X_valid1], axis=1)\n",
    "            \n",
    "        if model_type == 'BENCHMARK':\n",
    "            model = sm.OLS(y_train[num:], X_train[num:])\n",
    "            model = model.fit()\n",
    "            \n",
    "        elif model_type == 'MEAN':\n",
    "            from sklearn.neighbors import KNeighborsRegressor\n",
    "            k = len(y_train[num:])\n",
    "            \n",
    "            model = KNeighborsRegressor(n_neighbors=k)\n",
    "            model.fit(X_train[num:],y_train[num:])\n",
    "\n",
    "        elif model_type == 'RIDGE':\n",
    "            #define the ridge reg model\n",
    "            #set up different alpha values to try\n",
    "            alpha_ = (.0001, .001, .01, .1, 1, 10, 100, 1000)\n",
    "            rmse_valid = np.zeros([len(alpha_)])\n",
    "\n",
    "            #create loop to try different alphas and store validation error to pick best one\n",
    "            i = 0\n",
    "            for a in range(len(alpha_)):\n",
    "                reg = Ridge(alpha=alpha_[a])\n",
    "                reg.fit(X_train[num:],y_train[num:])\n",
    "                ridge_preds = reg.predict(X_train[num:])\n",
    "\n",
    "                #####################validation########################\n",
    "                valid_ridge_preds = pd.DataFrame(reg.predict(X_valid[shift_ord:]))\n",
    "                valid_ridge_preds = valid_ridge_preds.set_index(y_valid[shift_ord:].index)\n",
    "                valid_ridge_preds = rbY.inverse_transform(valid_ridge_preds)\n",
    "                rmse_valid[i] = np.sqrt(mean_squared_error(y_valid[shift_ord:], valid_ridge_preds)) #/ np.abs(np.mean(y_valid))\n",
    "                i += 1\n",
    "\n",
    "            ###########################################################################\n",
    "            #now use the model with the best validation RMSE###########################\n",
    "            plt.plot(np.arange(len(alpha_)),rmse_valid)\n",
    "            best_a=  np.argmin(rmse_valid)\n",
    "            best_alpha = alpha_[best_a]\n",
    "            model = Ridge(alpha=best_alpha)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        elif model_type == 'KNN':\n",
    "            from sklearn.neighbors import KNeighborsRegressor\n",
    "            k = np.arange(60)\n",
    "            rmse_valid = np.zeros([len(k)])\n",
    "            #create loop to try differnet alphas and store validation error to pick best one\n",
    "            i = 0\n",
    "            for a in range(len(k)):\n",
    "                mod = KNeighborsRegressor(n_neighbors=a+1)\n",
    "                mod.fit(X_train[num:],y_train[num:])\n",
    "                knn_preds = mod.predict(X_train[num:])\n",
    "\n",
    "                #####################validation########################\n",
    "                valid_knn_preds = pd.DataFrame(mod.predict(X_valid[shift_ord:]))\n",
    "                valid_knn_preds = valid_knn_preds.set_index(y_valid[shift_ord:].index)\n",
    "                valid_knn_preds = rbY.inverse_transform(valid_knn_preds)\n",
    "                rmse_valid[i] = np.sqrt(mean_squared_error(y_valid[shift_ord:], valid_knn_preds)) #/ np.abs(np.mean(y_valid))\n",
    "                i += 1\n",
    "\n",
    "            ###########################################################################\n",
    "            #now use the model with the best validation RMSE###########################\n",
    "            plt.plot(k, rmse_valid)\n",
    "            best_k =  np.argmin(rmse_valid) + 1\n",
    "            model = KNeighborsRegressor(n_neighbors=best_k)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        elif model_type == 'RF':\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "            feat = (X_train.shape[1] - 1)\n",
    "            trees = (10,25,50,75,100,150,250,500,1000)\n",
    "            max_feats = np.arange(1,feat) #(2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)\n",
    "            depth = (2,3,4,5,6)\n",
    "\n",
    "            rmse_valid = np.zeros([len(trees), len(max_feats), len(depth)])\n",
    "            for t in range(len(trees)):\n",
    "                for s in range(len(max_feats)):\n",
    "                    for d in range(len(depth)):\n",
    "\n",
    "                        mod = skl.ensemble.RandomForestRegressor(n_estimators=trees[t], max_features=max_feats[s], max_depth=depth[d], random_state=0)\n",
    "                        mod.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "                        #####################validation########################\n",
    "                        valid_rf_preds = pd.DataFrame(mod.predict(X_valid[shift_ord:]))\n",
    "                        valid_rf_preds = valid_rf_preds.set_index(y_valid[shift_ord:].index)\n",
    "                        valid_rf_preds = rbY.inverse_transform(valid_rf_preds)\n",
    "                        rmse_valid[t,s,d] = np.sqrt(mean_squared_error(y_valid[shift_ord:], valid_rf_preds)) \n",
    "\n",
    "            ###########################################################################\n",
    "            #now use the model with the best validation RMSE###########################\n",
    "            flat_index = np.argmin(rmse_valid)\n",
    "            best_combo =  np.unravel_index(flat_index, rmse_valid.shape)\n",
    "            best_t = best_combo[0]\n",
    "            best_s = best_combo[1]\n",
    "            best_d = best_combo[2]\n",
    "            model = skl.ensemble.RandomForestRegressor(n_estimators=trees[best_t], max_features=max_feats[best_s], max_depth=depth[best_d], random_state=0)\n",
    "            model.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "\n",
    "        elif model_type == 'SVR':\n",
    "            from sklearn.svm import SVR\n",
    "#             #normalize data to stabilize SVR\n",
    "#             rbX = RobustScaler()\n",
    "#             X_train1 = pd.DataFrame(rbX.fit_transform(X_train.iloc[num:,1:]))\n",
    "#             X_train1 = X_train1.set_index(X_train[num:].index)\n",
    "#             X_train = pd.concat([pd.DataFrame(X_train.iloc[num:,0]), X_train1], axis=1)\n",
    "#             rbY = RobustScaler()\n",
    "#             y_train = rbY.fit_transform(y_train[num:])\n",
    "            \n",
    "#             #normalize validation data \n",
    "#             X_valid1 = pd.DataFrame(rbX.transform(X_valid.iloc[shift_ord:,1:]))\n",
    "#             X_valid1 = X_valid1.set_index(X_valid[shift_ord:].index)\n",
    "#             X_valid = pd.concat([pd.DataFrame(X_valid.iloc[shift_ord:,0]), X_valid1], axis=1)\n",
    "\n",
    "            #set parameter values for cross validation\n",
    "            C_vals = (.0001, .0005, .001, .005,.01, .05, .1, .5, 1, 5, 10, 50, 100,500)\n",
    "            gam_vals = (.00001, .0001, .001,.01, .1,1)\n",
    "            rmse_valid = np.zeros([len(C_vals), len(gam_vals)])\n",
    "           \n",
    "            #make loop to test for different combinations of hyperparameters using validation set \n",
    "            for c in range(len(C_vals)):\n",
    "                for g in range(len(gam_vals)):\n",
    "                    model = SVR(kernel='rbf',C=C_vals[c], gamma=gam_vals[g])\n",
    "                    model.fit(X_train, y_train)\n",
    "\n",
    "                    valid_svr_preds = pd.DataFrame(model.predict(X_valid))\n",
    "                    valid_svr_preds = valid_svr_preds.set_index(y_valid[shift_ord:].index)\n",
    "                    valid_svr_preds = rbY.inverse_transform(valid_svr_preds)\n",
    "                    rmse_valid[c,g] = np.sqrt(mean_squared_error(y_valid[shift_ord:], valid_svr_preds))\n",
    "                    \n",
    "            #now use the model with the best validation RMSE###########################\n",
    "            flat_index = np.argmin(rmse_valid)\n",
    "            best_combo =  np.unravel_index(flat_index, rmse_valid.shape)\n",
    "            best_c = best_combo[0]\n",
    "            best_g = best_combo[1]\n",
    "            model = SVR(kernel='rbf',C=C_vals[best_c], gamma=gam_vals[best_g])\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        elif model_type == 'LSTM':\n",
    "            print('hello!!!!!')\n",
    "            #normalize data to stabilize training \n",
    "            rbX = StandardScaler()\n",
    "            #X_train1 = pd.DataFrame(rbX.fit_transform(X_train.iloc[num:,1:]))\n",
    "            #X_train1 = X_train1.set_index(X_train[num:].index)\n",
    "            X_train1 = rbX.fit_transform(X_train.iloc[num:,1:])\n",
    "            X_train = np.concatenate((X_train.iloc[num:,:1], X_train1), axis=1)\n",
    "            print(X_train.shape)\n",
    "            train_size = X_train.shape[0]\n",
    "            dims = X_train.shape[1]\n",
    "            X_train = np.reshape(X_train, (X_train.shape[0],1,X_train.shape[1]))\n",
    "            print(X_train.shape)\n",
    "            \n",
    "            rbY = StandardScaler()\n",
    "            y_train = rbY.fit_transform(y_train[num:])\n",
    "\n",
    "            #normalize validation data \n",
    "            #X_valid1 = pd.DataFrame(rbX.transform(X_valid.iloc[shift_ord:,1:]))\n",
    "            #X_valid1 = X_valid1.set_index(X_valid[shift_ord:].index)\n",
    "            X_valid1 = rbX.transform(X_valid.iloc[shift_ord:,1:])\n",
    "            X_valid = np.concatenate((X_valid.iloc[shift_ord:,:1], X_valid1), axis=1)\n",
    "            print(X_valid.shape)\n",
    "            X_valid = np.reshape(X_valid, (X_valid.shape[0],1,X_valid.shape[1]))\n",
    "            \n",
    "            #set range of hyperparameters\n",
    "            node = (4,8,16,32,64)\n",
    "            learn_rate = (.0001, .001, .01, .1)\n",
    "            eps = 100\n",
    "\n",
    "            rmse_valid = np.zeros([len(node), len(learn_rate)])\n",
    "            for n in range(len(node)): \n",
    "                for rate in range(len(learn_rate)): \n",
    "                    model = Sequential()\n",
    "                    model.add(LSTM(node[n], input_shape=(1, dims)))\n",
    "                    model.add(Dropout(0.5))\n",
    "                    #model.add(Dense(node[n], activation = 'tanh'))\n",
    "                    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "                    rmsp = optimizers.RMSprop(lr=learn_rate[rate])\n",
    "                    model.compile(loss='mse',\n",
    "                                  optimizer=rmsp)\n",
    "                    model.fit(X_train, y_train, epochs=eps, batch_size=train_size)\n",
    "                    \n",
    "                    valid_lstm_preds = pd.DataFrame(model.predict(X_valid))\n",
    "                    valid_lstm_preds = valid_lstm_preds.set_index(y_valid[shift_ord:].index)\n",
    "                    valid_lstm_preds = rbY.inverse_transform(valid_lstm_preds)\n",
    "                    rmse_valid[n,rate] = np.sqrt(mean_squared_error(y_valid[shift_ord:], valid_lstm_preds))\n",
    "                    \n",
    "                    \n",
    "            #now use the model with the best validation RMSE###########################\n",
    "            flat_index = np.argmin(rmse_valid)\n",
    "            best_combo =  np.unravel_index(flat_index, rmse_valid.shape)\n",
    "            best_n = best_combo[0]\n",
    "            best_rate = best_combo[1]\n",
    "            \n",
    "            model = Sequential()\n",
    "            model.add(LSTM(node[best_n], input_shape=(1, dims)))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(node[best_n], activation = 'tanh'))\n",
    "            model.add(Dense(1, activation='linear'))\n",
    "\n",
    "            rmsp = optimizers.RMSprop(lr=learn_rate[best_rate])\n",
    "            model.compile(loss='mse',\n",
    "                          optimizer=rmsp)\n",
    "            model.fit(X_train, y_train, epochs=eps, batch_size=1)\n",
    "            print('best nodes =', best_n, '  best rate = ', best_rate)\n",
    "\n",
    "        print(model)\n",
    "\n",
    "        return model\n",
    "\n",
    "    #input number n points to predict ahead using other predictions\n",
    "    #also input the true values to make predictions\n",
    "    #use to make preds if you used only AR values\n",
    "    def pred_ahead_AR(n, X_in, X_train, y_train, model, model_type):\n",
    "        #get number of points\n",
    "            \n",
    "        if model_type != 'LSTM':\n",
    "            rbX = RobustScaler()\n",
    "            X_train = rbX.fit_transform(X_train)\n",
    "            X_in = pd.DataFrame(rbX.transform(X_in))\n",
    "\n",
    "        if model_type =='LSTM':\n",
    "            rbX = StandardScaler()\n",
    "            X_train = rbX.fit_transform(X_train)\n",
    "            X_in = pd.DataFrame(rbX.transform(X_in))\n",
    "\n",
    "        X = X_in.iloc[:,1:].values\n",
    "        t = X.shape[0]\n",
    "        num_lags = X.shape[1]\n",
    "\n",
    "        y_hat = np.zeros([t,n])\n",
    "        y_hat[:,0] = X[:,0]\n",
    "        new_X = np.zeros(X.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if model_type == 'MEAN':\n",
    "            y_hat[:,:] = np.mean(y_train)\n",
    "\n",
    "        else:\n",
    "                #loop through number of months to predict into.\n",
    "            #each additional month shifts the input data so that we have some\n",
    "            #of the original data and then also the relevant points that we have forecasted already\n",
    "            for j in range(n):\n",
    "                if num_lags >= j+1:\n",
    "                    new_X = np.concatenate((X[:,j:], y_hat[:,:j]),axis=1)\n",
    "                    new_X = sm.add_constant(new_X)\n",
    "                    if model_type =='LSTM':\n",
    "                        new_X = np.reshape(new_X, (new_X.shape[0], 1, new_X.shape[1]))\n",
    "                    y_hat[:,j] = (model.predict(new_X)).reshape(t,)\n",
    "                else:\n",
    "                    new_X = y_hat[:, (j-num_lags):j]\n",
    "                    new_X = sm.add_constant(new_X)\n",
    "                    if model_type =='LSTM':\n",
    "                        new_X = np.reshape(new_X, (new_X.shape[0], 1, new_X.shape[1]))\n",
    "                    y_hat[:,j] = (model.predict(new_X)).reshape(t,)\n",
    "\n",
    "            if model_type != 'LSTM': #or model_type =='LSTM':\n",
    "                rbY = RobustScaler()\n",
    "                Y = rbY.fit_transform(y_train)\n",
    "                y_hat = rbY.inverse_transform(y_hat)\n",
    "\n",
    "            if model_type =='LSTM':\n",
    "                rbY = StandardScaler()\n",
    "                Y = rbY.fit_transform(y_train)\n",
    "                y_hat = rbY.inverse_transform(y_hat)\n",
    "\n",
    "        return pd.DataFrame(y_hat)\n",
    "\n",
    "        #use to make preds if you used a combo of mortgage and AR vals\n",
    "    def pred_ahead_combo(n, num_lags, X_in,X_train,y_train, model,model_type):\n",
    "            #get number of points\n",
    "            if model_type != 'LSTM':\n",
    "                rbX = RobustScaler()\n",
    "                X_train = rbX.fit_transform(X_train)\n",
    "                X_in = pd.DataFrame(rbX.transform(X_in))\n",
    "\n",
    "            if model_type =='LSTM':\n",
    "                rbX = StandardScaler()\n",
    "                X_train = rbX.fit_transform(X_train)\n",
    "                X_in = pd.DataFrame(rbX.transform(X_in))\n",
    "\n",
    "            X = X_in.iloc[:,1:].values\n",
    "            t = X.shape[0]\n",
    "\n",
    "            y_hat = np.zeros([t,n])\n",
    "            y_hat[:,0] = X[:,0]\n",
    "            new_X = np.zeros(X.shape)\n",
    "            \n",
    "              \n",
    "            if model_type == 'MEAN':\n",
    "                y_hat[:,:] = np.mean(y_train)\n",
    "        \n",
    "            else:\n",
    "\n",
    "                #loop through number of months to predict into.\n",
    "                #each additional month shifts the input data so that we have some\n",
    "                #of the original data and then also the relevant points that we have forecasted already\n",
    "                for j in range(n):\n",
    "                    \n",
    "                    if j+1 > num_lags:\n",
    "                        new_X1 = y_hat[:,j-num_lags:j]\n",
    "                        new_X = np.concatenate((new_X1, X[:,num_lags:]), axis=1)\n",
    "                        new_X = sm.add_constant(new_X)\n",
    "                        if model_type =='LSTM':\n",
    "                            new_X = np.reshape(new_X, (new_X.shape[0], 1, new_X.shape[1]))\n",
    "                        y_hat[:,j] = (model.predict(new_X)).reshape(t,)\n",
    "                    else:\n",
    "                        new_X1 = np.concatenate((X[:,j:num_lags], y_hat[:,:j]),axis=1)\n",
    "                        new_X = np.concatenate((new_X1, X[:,num_lags:]), axis=1)\n",
    "                        new_X = sm.add_constant(new_X)\n",
    "                        if model_type =='LSTM':\n",
    "                            new_X = np.reshape(new_X, (new_X.shape[0], 1, new_X.shape[1]))\n",
    "                        y_hat[:,j] = (model.predict(new_X)).reshape(t,)\n",
    "\n",
    "\n",
    "                if model_type != 'LSTM':\n",
    "                    rbY = RobustScaler()\n",
    "                    Y = rbY.fit_transform(y_train)\n",
    "                    y_hat = rbY.inverse_transform(y_hat)\n",
    "\n",
    "                if model_type =='LSTM':\n",
    "                    rbY = StandardScaler()\n",
    "                    Y = rbY.fit_transform(y_train)\n",
    "                    y_hat = rbY.inverse_transform(y_hat)\n",
    "\n",
    "            return pd.DataFrame(y_hat)\n",
    "        \n",
    "   \n",
    "\n",
    "    def predict_things(model_type, X_train, X_valid, X_test,y_train, y_valid, y_test, y_hat, y_hat_valid, y_hat_test, num, model, month_forecast, shift_ord):\n",
    "\n",
    "            train_size = len(X_train)\n",
    "            valid_size = len(X_valid)\n",
    "            filepath = '/Users/abbysuckow/Desktop/' + model_type +'/' + model_type\n",
    "\n",
    "            #if we built the model based on shifted data\n",
    "            if shift_ord > 0:\n",
    "                preds = pd.DataFrame(model.predict(X_train[num:]))\n",
    "                preds = preds.set_index(y_train[num:].index)\n",
    "\n",
    "                \n",
    "                rmse_train = np.sqrt(mean_squared_error(y_train[num:], preds))  \n",
    "                MAE_train = mean_absolute_error(y_train[num:], preds)\n",
    "\n",
    "                #plot the training data\n",
    "                plt.plot(y_train, color = 'blue')\n",
    "                plt.plot(preds, color='red')\n",
    "                plt.title('Shifting Data - Train Predictions ' + str(month_forecast) + ' months ahead')\n",
    "                plt.show()\n",
    "\n",
    "                #validation set\n",
    "                valid_preds = pd.DataFrame(model.predict(X_valid))\n",
    "                valid_preds = valid_preds.set_index(y_valid.index)\n",
    "\n",
    "                rmse_valid = np.sqrt(mean_squared_error(y_valid[month_forecast:], valid_preds[month_forecast:])) #/ np.abs(np.mean(y_valid[month_forecast:]))\n",
    "                MAE_valid = mean_absolute_error(y_valid[month_forecast:], valid_preds[month_forecast:])\n",
    "\n",
    "                plt.plot(y_valid, color = 'blue')\n",
    "                plt.plot(valid_preds, color='red')\n",
    "                plt.title('Shifting Data - Validation Predictions' + str(month_forecast) + '  months ahead')\n",
    "                plt.show()\n",
    "\n",
    "                #test set\n",
    "                test_preds = pd.DataFrame(model.predict(X_test))\n",
    "                test_preds = test_preds.set_index(y_test.index)\n",
    "\n",
    "                rmse_test = np.sqrt(mean_squared_error(y_test[month_forecast:], test_preds[month_forecast:])) #/ np.abs(np.mean(y_test[month_forecast:]))\n",
    "                MAE_test = mean_absolute_error(y_test[month_forecast:], test_preds[month_forecast:])\n",
    "\n",
    "                plt.plot(y_test, color = 'blue')\n",
    "                plt.plot(test_preds, color='red')\n",
    "                plt.title('Shifting Data - Test Predictions' + str(month_forecast) + ' months ahead')\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "                #make a table of the error measures\n",
    "                row_labels = ('RMSE', 'MAE')\n",
    "                col_labels = ('Training', 'Validation', 'Test')\n",
    "                error_measures = ([rmse_train, rmse_valid, rmse_test], [MAE_train, MAE_valid, MAE_test])\n",
    "                fig, ax = plt.subplots()\n",
    "                fig.set_size_inches(8.5, 2.5)\n",
    "\n",
    "                # Hide axes\n",
    "                ax.xaxis.set_visible(False)\n",
    "                ax.yaxis.set_visible(False)\n",
    "                plt.title(str( month_forecast) + ' months ahead error measures - shifting data')\n",
    "                ax.table(cellText=error_measures,rowLabels=row_labels,colLabels=col_labels,loc='center')\n",
    "                plt.show()\n",
    "\n",
    "                use = preds\n",
    "                use_valid = valid_preds\n",
    "                use_test = test_preds\n",
    "\n",
    "            #if we want to make predictions on predictions:\n",
    "            else:\n",
    "\n",
    "                #create loop to store MSE for different prediction intervals\n",
    "                y_hat_mse = np.zeros([month_forecast,1])\n",
    "                for f in range(month_forecast):\n",
    "                    y_hat_mse[f,0] = np.sqrt(mean_squared_error(y_train.iloc[num+f+1:], y_hat.iloc[:][f].shift(f+1)[f+1:])) #/ np.abs(np.mean(y.iloc[num+f+1:train_size]))\n",
    "\n",
    "                pd.DataFrame(y_hat_mse).plot()\n",
    "                plt.title('Training RMSE for different month prediction intervals')\n",
    "                plt.xlabel('Number of Months into the Future')\n",
    "                plt.ylabel('RMSE')\n",
    "                plt.savefig(filepath+'_RMSE_' +str(month_forecast))\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "                use = pd.DataFrame(y_hat[month_forecast-1])\n",
    "                use = use.set_index(y_train[num:].index + pd.DateOffset(months=month_forecast))\n",
    "                \n",
    "                \n",
    "                rmse_train= (np.sqrt(mean_squared_error(y_train.iloc[num+month_forecast:], use[:len(use)-month_forecast])))  \n",
    "                nrmse_train = \"{0:.5f}\".format(rmse_train / np.std(y_train.iloc[num+month_forecast:])[0])\n",
    "                rmse_train = \"{0:.5f}\".format(rmse_train)\n",
    "                MAE_train = \"{0:.5f}\".format(mean_absolute_error(y_train.iloc[num+month_forecast:], use[:len(use)-month_forecast]))\n",
    "\n",
    "                #plot\n",
    "                plt.plot(y_train[num+month_forecast:], color = 'blue')\n",
    "                plt.plot(use, color='red')\n",
    "                plt.title('Training Predictions ' + str(month_forecast) + ' Month(s) Ahead')\n",
    "                plt.savefig(filepath+'_train_' +str(month_forecast))\n",
    "                plt.show()\n",
    "\n",
    "                #validation set\n",
    "                use_valid = pd.DataFrame(y_hat_valid[month_forecast-1])\n",
    "                use_valid = use_valid.set_index(y_valid.index + pd.DateOffset(months=month_forecast))\n",
    "\n",
    "                 \n",
    "                rmse_valid = (np.sqrt(mean_squared_error(y_valid[month_forecast:], use_valid[:len(use_valid)-month_forecast])))\n",
    "                nrmse_valid = \"{0:.5f}\".format(rmse_valid / np.std(y_valid.iloc[month_forecast:])[0])\n",
    "                rmse_valid = \"{0:.5f}\".format(rmse_valid)\n",
    "                MAE_valid = \"{0:.5f}\".format(mean_absolute_error(y_valid[month_forecast:], use_valid[:len(use_valid)-month_forecast]))\n",
    "\n",
    "                plt.plot(y_valid[month_forecast:], color = 'blue')\n",
    "                plt.plot(use_valid, color='red')\n",
    "                plt.title('Validation Predictions ' + str(month_forecast) + ' Month(s) Ahead')\n",
    "                plt.savefig(filepath+'_valid_' +str(month_forecast))\n",
    "                plt.show()\n",
    "\n",
    "                #test set\n",
    "                use_test = pd.DataFrame(y_hat_test[month_forecast-1])\n",
    "                use_test = use_test.set_index(y_test.index + pd.DateOffset(months=month_forecast))\n",
    "\n",
    "\n",
    "                rmse_test = (np.sqrt(mean_squared_error(y_test[month_forecast:], use_test[:len(use_test)-month_forecast])))\n",
    "                nrmse_test = \"{0:.5f}\".format(rmse_test / np.std(y_test.iloc[month_forecast:])[0])\n",
    "                rmse_test = \"{0:.5f}\".format(rmse_test)\n",
    "                MAE_test = \"{0:.5f}\".format(mean_absolute_error(y_test[month_forecast:], use_test[:len(use_test)-month_forecast]))\n",
    "\n",
    "                plt.plot(y_test[month_forecast:], color = 'blue')\n",
    "                plt.plot(use_test, color='red')\n",
    "                plt.title('Test Predictions ' + str(month_forecast) + ' Month(s) Ahead')\n",
    "                plt.savefig(filepath+'_test_'+str(month_forecast))\n",
    "                plt.show()\n",
    "\n",
    "                #make a table of the error measures\n",
    "                row_labels = ('RMSE', 'NRMSE', 'MAE')\n",
    "                col_labels = ('Training', 'Validation', 'Test')\n",
    "                error_measures = ([rmse_train, rmse_valid, rmse_test],[nrmse_train, nrmse_valid, nrmse_test], [MAE_train, MAE_valid, MAE_test])\n",
    "                fig, ax = plt.subplots()\n",
    "                fig.set_size_inches(5.5, 2.5)\n",
    "\n",
    "                # Hide axes\n",
    "                ax.axis('off')\n",
    "                ax.axis('tight')\n",
    "                ax.xaxis.set_visible(False)\n",
    "                ax.yaxis.set_visible(False)\n",
    "                plt.title(str( month_forecast) + ' Month(s) Ahead Error Measures', fontsize=10)\n",
    "                ax.table(cellText=error_measures,rowLabels=row_labels,colLabels=col_labels,  loc='center',bbox=[0, 0, 1, 1])\n",
    "\n",
    "                plt.savefig(filepath+'_table_'+str(month_forecast), bbox_inches='tight')\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "            return  rmse_train, rmse_valid, rmse_test, use, use_valid, use_test\n",
    "\n",
    "        #this function adjusts the predictions to the original values and creates\n",
    "        #plots and error measures based on the original scale of the data.\n",
    "    def adjusted_preds(model_type, y_hat, y_hat_valid, y_hat_test, CS_dat, perc_adj_CS_dat, dif_order, adj_CS_dat, new_PCE, train_size, valid_size, month_forecast, num):\n",
    "\n",
    "        filepath = '/Users/abbysuckow/Desktop/' + model_type +'/' + model_type\n",
    "\n",
    "        unadj_y_hat = fix_data.switch_back(y_hat,perc_adj_CS_dat[num-dif_order+month_forecast:], dif_order,month_forecast,adj_CS_dat[num:], new_PCE[month_forecast+num:train_size+month_forecast])\n",
    "        unadj_y_hat = pd.DataFrame(unadj_y_hat).set_index(new_PCE[month_forecast+num:train_size+month_forecast].index)\n",
    "        un = pd.DataFrame(fix_data.switch_back(y_hat,perc_adj_CS_dat[num-dif_order+month_forecast:], dif_order,month_forecast,adj_CS_dat[num:], new_PCE[month_forecast+num:train_size+month_forecast]))\n",
    "        un = un.set_index(y_hat.index)\n",
    "        rmse_train= np.sqrt(mean_squared_error(CS_dat.iloc[num+month_forecast:train_size+month_forecast], unadj_y_hat))\n",
    "        MAE_train = mean_absolute_error(CS_dat.iloc[num+month_forecast:train_size+month_forecast], unadj_y_hat)\n",
    "\n",
    "        unadj_y_hat_v = fix_data.switch_back(y_hat_valid,perc_adj_CS_dat[train_size-dif_order+month_forecast:], dif_order,month_forecast,adj_CS_dat[train_size:], new_PCE[month_forecast+train_size:train_size+month_forecast+valid_size])\n",
    "        unadj_y_hat_v = pd.DataFrame(unadj_y_hat_v).set_index(new_PCE[month_forecast+train_size:train_size+month_forecast+valid_size].index)\n",
    "        rmse_valid = np.sqrt(mean_squared_error(CS_dat.iloc[train_size+month_forecast:train_size+valid_size+month_forecast], unadj_y_hat_v))\n",
    "        MAE_valid = mean_absolute_error(CS_dat.iloc[train_size+month_forecast:train_size+valid_size+month_forecast], unadj_y_hat_v)\n",
    "\n",
    "        unadj_y_hat_t = fix_data.switch_back(y_hat_test[:len(new_PCE[month_forecast+train_size+valid_size:])],perc_adj_CS_dat[train_size+valid_size-dif_order+month_forecast:], dif_order,month_forecast,adj_CS_dat[train_size+valid_size:], new_PCE[month_forecast+train_size+valid_size:])\n",
    "        unadj_y_hat_t = pd.DataFrame(unadj_y_hat_t).set_index(new_PCE[month_forecast+train_size+valid_size:].index)\n",
    "        rmse_test = np.sqrt(mean_squared_error(CS_dat.iloc[train_size+valid_size+month_forecast:len(CS_dat)-1],unadj_y_hat_t[:len(new_PCE[month_forecast+train_size+valid_size:])]))\n",
    "        MAE_test = mean_absolute_error(CS_dat.iloc[train_size+valid_size+month_forecast:len(CS_dat)-1],unadj_y_hat_t[:len(new_PCE[month_forecast+train_size+valid_size:])])\n",
    "\n",
    "\n",
    "        #plots the predictions\n",
    "        #plt.plot(unadj_y_hat)\n",
    "        plt.plot(un)\n",
    "        plt.plot(unadj_y_hat_v)\n",
    "        plt.plot(unadj_y_hat_t)\n",
    "        plt.plot(CS_dat[num+month_forecast:])\n",
    "\n",
    "        plt.ylim(50,300)\n",
    "        plt.savefig(filepath+'_unadj_'+str(month_forecast))\n",
    "        plt.show()\n",
    "\n",
    "        #error tables\n",
    "        row_labels = ('RMSE', 'MAE')\n",
    "        col_labels = ('Training', 'Validation', 'Test')\n",
    "        error_measures = ([rmse_train, rmse_valid, rmse_test], [MAE_train, MAE_valid, MAE_test])\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(8.5, 2.5)\n",
    "\n",
    "        # Hide axes\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        plt.title(str( month_forecast) + ' month(s) ahead error measures')\n",
    "        ax.table(cellText=error_measures,rowLabels=row_labels,colLabels=col_labels, bbox=[0, -0.3, 1, 0.275])\n",
    "        plt.show()\n",
    "\n",
    "        return unadj_y_hat, unadj_y_hat_v, unadj_y_hat_t\n",
    "\n",
    "\n",
    "    def slope_analysis(y_hat, y_tru,model_type,month_forecast):\n",
    "        filepath = '/Users/abbysuckow/Desktop/' + model_type +'/' + model_type\n",
    "        yhmax = np.amax(y_hat)\n",
    "        yhmin = np.min(y_hat)\n",
    "\n",
    "        ytmax = np.amax(y_tru)\n",
    "        ytmin = np.min(y_tru)\n",
    "\n",
    "        if yhmax > ytmax[0]:\n",
    "            ymax = yhmax +.1*yhmax\n",
    "        else:\n",
    "            ymax = ytmax[0] + .1*(ytmax[0])\n",
    "        if yhmin < ytmin[0]:\n",
    "            ymin = yhmin - .1*yhmin\n",
    "        else:\n",
    "            ymin = ytmin[0] - .1*(ytmin[0])\n",
    "\n",
    "        if ymax > 1.5:\n",
    "            step = 1\n",
    "        else:\n",
    "            step = .1*ymax\n",
    "\n",
    "\n",
    "        plt.scatter(y_tru, y_hat)\n",
    "        plt.plot(np.arange(ymin,ymax,step=step), np.arange(ymin,ymax, step=step))\n",
    "        plt.xlabel('Truth')\n",
    "        plt.ylabel('Predictions')\n",
    "        plt.title('Predictions versus Truth')\n",
    "        plt.xlim(ymin, ymax)\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.savefig(filepath+'_slope_'+str(month_forecast))\n",
    "        plt.show()\n",
    "\n",
    "        y_hat = sm.add_constant(y_hat)\n",
    "        model = sm.OLS(y_tru, y_hat)\n",
    "        model = model.fit()\n",
    "        print(model.summary())\n",
    "\n",
    "        plt.rc('figure', figsize=(12, 7))\n",
    "        plt.text(0.01, 0.05, str(model.summary()), {'fontsize': 10}, fontproperties = 'monospace') # approach improved by OP -> monospace!\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filepath+'_ols_'+str(month_forecast))\n",
    "\n",
    "        return\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
